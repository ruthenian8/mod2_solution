# -*- coding: utf-8 -*-
"""DZ.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lnkjctLeX3OKf-o7aT55BRwJTVd7SgwI

## 1 часть
"""

import pandas as pd
import json
import lxml.html as html
import requests
from nltk.tokenize import RegexpTokenizer
tokenizer = RegexpTokenizer(r"[а-яА-ЯёЁ]+")

poetStr = ""
with open("dom.txt", "r") as file:
  poetStr = file.read()

poetStr = poetStr.lower()
poet = tokenizer.tokenize(poetStr)

dictionary = {}
for word in poet:
  if not word in dictionary.keys():
    dictionary[word] = 1
  else:
    dictionary[word] += 1

slovar = pd.DataFrame.from_dict({n: [dictionary[n]] for n in dictionary.keys()}, 
                                "index", 
                                columns=["quantity"])

slovar = slovar.sort_values(by="quantity", ascending=False)

slovar.to_csv("slovar.csv")

"""## 2 часть"""

import pymorphy2

analyzer = pymorphy2.MorphAnalyzer()

lemVersion = [analyzer.parse(n)[0].normal_form for n in poet]

oosList = list(filter(lambda x: "оо" in x, lemVersion))

with open(file="oo.txt", mode="w+", encoding="UTF-8") as oo:
  oo.write("\n".join(oosList))

"""## Часть 2.1"""

page = requests.get("http://lib.ru/POEZIQ/PESSOA/lirika.txt")

page = html.fromstring(page.content.decode("KOI8-R"))

content = page.text_content()
content = content.lower()

content = tokenizer.tokenize(content)

dictTheSecond = {}
for word in content:
  if not word in dictTheSecond.keys():
    dictTheSecond[word] = 1
  else:
    dictTheSecond[word] += 1

dictTheSecond = {n: str(dictTheSecond[n]) for n in sorted(dictTheSecond.keys())}

# js = json.dumps(dictTheSecond, ensure_ascii=False).encode("UTF-8")
with open("slovar.json", "w+", encoding="UTF-8") as newFile:
  json.dump(dictTheSecond, newFile, ensure_ascii=False)